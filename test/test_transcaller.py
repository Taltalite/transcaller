import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader, Subset
import h5py
import os
import argparse
from tqdm import tqdm
import numpy as np
import random
import editdistance  # ç”¨äºè®¡ç®— Levenshtein è·ç¦»
import matplotlib.pyplot as plt

# --- å…³é”®å¯¼å…¥ ---
# ç¡®ä¿ 'model.py' (æˆ–æ‚¨ä¿å­˜å®ƒçš„åœ°æ–¹) å¯ä»¥åœ¨ Python è·¯å¾„ä¸­è¢«æ‰¾åˆ°
import sys
try:
    sys.path.append('/home/lijy/workspace/') # æ›¿æ¢ä¸ºæ‚¨çš„é¡¹ç›®è·¯å¾„
    from my_basecaller.model.transcaller_light import TranscallerLight
except ImportError:
    print("="*80)
    print("é”™è¯¯: æ— æ³•å¯¼å…¥ 'TranscallerLight'ã€‚")
    print("è¯·ç¡®ä¿æ‚¨çš„æ¨¡å‹ä»£ç åœ¨ Python è·¯å¾„ä¸­ã€‚")
    print("="*80)
    exit(1)

# ==========================================================================================
# æ­¥éª¤ 1: HDF5 æ•°æ®é›†ç±» (ä¸ train.py ç›¸åŒ)
# ==========================================================================================

class BasecallerHDF5Dataset(Dataset):
    """
    ç”¨äºè¯»å– HDF5 æ ¼å¼çš„ Basecaller æ•°æ®é›†çš„è‡ªå®šä¹‰ Datasetã€‚
    """
    def __init__(self, h5_file_path):
        super().__init__()
        self.h5_file_path = h5_file_path
        
        try:
            with h5py.File(self.h5_file_path, 'r') as f:
                self.dataset_len = f['event'].shape[0]
        except Exception as e:
            print(f"æ‰“å¼€æˆ–éªŒè¯ HDF5 æ–‡ä»¶ {h5_file_path} å¤±è´¥: {e}")
            raise
            
        self.h5_file = None
        self.pid = None 

    def __len__(self):
        return self.dataset_len

    def __getitem__(self, idx):
        if self.pid != os.getpid():
            if self.h5_file:
                self.h5_file.close() 
            self.h5_file = h5py.File(self.h5_file_path, 'r')
            self.pid = os.getpid()
            
        # ä»…åœ¨è¯„ä¼°æ—¶ï¼Œæˆ‘ä»¬æ‰éœ€è¦æ‰€æœ‰æ•°æ®
        event = self.h5_file['event'][idx] 
        label = self.h5_file['label'][idx] 
        label_len = self.h5_file['label_len'][idx]
        
        event_tensor = torch.from_numpy(event).float()
        label_tensor = torch.from_numpy(label).long()
        label_len_tensor = torch.tensor(label_len).long()
        
        return event_tensor, label_tensor, label_len_tensor

# ==========================================================================================
# æ­¥éª¤ 2: CTC è´ªå©ªè§£ç å™¨
# ==========================================================================================

def greedy_decode(log_probs, blank_id=4):
    """
    æ‰§è¡Œ CTC è´ªå©ªè§£ç  (Best Path Decoding)ã€‚

    Args:
        log_probs (Tensor): æ¨¡å‹çš„è¾“å‡º (T, B, C)
        blank_id (int): ç©ºç™½æ ‡ç­¾çš„ç´¢å¼•

    Returns:
        list[list[int]]: è§£ç åçš„ batchï¼Œ(B, Seq)
    """
    
    # 1. æ‰¾åˆ°æ¯ä¸ªæ—¶é—´æ­¥æ¦‚ç‡æœ€é«˜çš„ token
    # (T, B, C) -> (T, B)
    best_path = torch.argmax(log_probs, dim=-1)
    
    decoded_batch = []
    batch_size = best_path.shape[1]
    
    # 2. éå† batch ä¸­çš„æ¯ä¸ªæ ·æœ¬
    for i in range(batch_size):
        seq = best_path[:, i]
        
        # 3. æŠ˜å é‡å¤çš„ token
        # [0, 0, 1, 1, 1, 0, 2, 2] -> [0, 1, 0, 2]
        collapsed_seq = []
        last_token = -1
        for token in seq:
            if token.item() != last_token:
                collapsed_seq.append(token.item())
                last_token = token.item()
                
        # 4. ç§»é™¤ blank token
        # [0, 1, 4, 0, 2, 4] -> [0, 1, 0, 2]
        final_seq = [t for t in collapsed_seq if t != blank_id]
        decoded_batch.append(final_seq)
        
    return decoded_batch

# ==========================================================================================
# æ­¥éª¤ 3: è¯„ä¼°å‡½æ•°
# ==========================================================================================

def evaluate_accuracy(model, data_loader, device, output_len, blank_id):
    """
    åœ¨æµ‹è¯•é›†ä¸Šè®¡ç®— Read Accuracy å’Œ Base Accuracyã€‚
    """
    model.eval()
    
    total_reads = 0
    correct_reads = 0
    total_edits = 0
    total_base_len = 0
    
    progress_bar = tqdm(data_loader, desc='[è¯„ä¼°ä¸­]', leave=True)
    
    with torch.no_grad():
        for events, labels, label_lengths in progress_bar:
            events = events.to(device, non_blocking=True)
            # labels å’Œ label_lengths ä¿ç•™åœ¨ CPU ä¸Šï¼Œå› ä¸ºè§£ç å’Œæ¯”è¾ƒåœ¨ CPU ä¸Šè¿›è¡Œ
            
            # 1. å‰å‘ä¼ æ’­
            log_probs = model(events) # (T, B, C)
            
            # 2. CTC è´ªå©ªè§£ç 
            # (T, B, C) -> list[list[int]] (é•¿åº¦ä¸º B)
            decoded_batch = greedy_decode(log_probs, blank_id)
            
            # 3. é€ä¸ªæ ·æœ¬æ¯”è¾ƒ
            for i in range(len(decoded_batch)):
                true_label_ids = labels[i][:label_lengths[i]].tolist()
                pred_label_ids = decoded_batch[i]
                
                # 3a. è®¡ç®— Read Accuracy
                if true_label_ids == pred_label_ids:
                    correct_reads += 1
                
                # 3b. è®¡ç®— Base Accuracy (ä½¿ç”¨ Levenshtein è·ç¦»)
                edits = editdistance.eval(true_label_ids, pred_label_ids)
                total_edits += edits
                total_base_len += len(true_label_ids)
                
                total_reads += 1
    
    read_accuracy = (correct_reads / total_reads) * 100
    # Base Accuracy = 1.0 - (ç¼–è¾‘è·ç¦» / çœŸå®é•¿åº¦)
    base_accuracy = (1.0 - (total_edits / total_base_len)) * 100
    
    return read_accuracy, base_accuracy

# ==========================================================================================
# æ­¥éª¤ 4: å¯è§†åŒ–å‡½æ•°
# ==========================================================================================

def visualize_one_sample(model, data_loader, device, token_map, blank_id, output_path):
    """
    è¿è¡Œä¸€ä¸ª batchï¼Œå¹¶å¯è§†åŒ–ç¬¬ä¸€ä¸ªæ ·æœ¬ã€‚
    """
    model.eval()
    
    print("\n" + "="*80)
    print("ç”Ÿæˆå•ä¸€æ ·æœ¬å¯è§†åŒ–...")
    
    with torch.no_grad():
        # 1. è·å–ä¸€ä¸ª batch
        try:
            events, labels, label_lengths = next(iter(data_loader))
        except StopIteration:
            print("é”™è¯¯: data_loader ä¸ºç©ºã€‚")
            return
            
        events = events.to(device)
        
        # 2. è¿è¡Œæ¨¡å‹
        log_probs = model(events) # (T, B, C)
        
        # 3. é€‰æ‹©ç¬¬ä¸€ä¸ªæ ·æœ¬è¿›è¡Œåˆ†æ
        i = 0 
        sample_log_probs = log_probs[:, i, :] # (T, C)
        
        # 4. è§£ç ç¬¬ä¸€ä¸ªæ ·æœ¬
        pred_label_ids = greedy_decode(log_probs, blank_id)[i]
        
        # 5. è·å–çœŸå®æ ‡ç­¾
        true_label_ids = labels[i][:label_lengths[i]].tolist()
        
        # 6. å°† ID è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        # token_map = {0: 'A', 1: 'C', 2: 'G', 3: 'T', 4: '<B>'}
        true_str = "".join([token_map.get(t, '?') for t in true_label_ids])
        pred_str = "".join([token_map.get(t, '?') for t in pred_label_ids])
        
        # 7. (è¾“å‡º 1) æ‰“å°æ–‡æœ¬å¯¹æ¯”
        print(f"æ ·æœ¬ {i} ç»“æœ:")
        print(f"  çœŸå® (True): {true_str}")
        print(f"  é¢„æµ‹ (Pred): {pred_str}")
        
        # 8. (è¾“å‡º 2) ç»˜åˆ¶æ¦‚ç‡å›¾
        # (T, C) -> (C, T)
        probs = torch.exp(sample_log_probs).cpu().numpy().T
        
        plt.figure(figsize=(20, 6))
        plt.imshow(probs, aspect='auto', interpolation='nearest', cmap='viridis')
        
        # è®¾ç½® Y è½´æ ‡ç­¾
        plt.yticks(ticks=range(len(token_map)), labels=token_map.values())
        
        plt.xlabel("æ¨¡å‹è¾“å‡ºæ—¶é—´æ­¥ (Timestep)")
        plt.ylabel("ç¢±åŸº")
        plt.title("Basecalling æ¦‚ç‡å›¾ (å•ä¸€æ ·æœ¬)")
        plt.colorbar(label="æ¦‚ç‡")
        
        plt.tight_layout()
        plt.savefig(output_path)
        print(f"å¯è§†åŒ–å›¾åƒå·²ä¿å­˜è‡³: {output_path}")
        print("="*80)

# ==========================================================================================
# æ­¥éª¤ 5: ä¸»å‡½æ•°
# ==========================================================================================

def main(args):
    
    # --- 1. è®¾ç½®ç¯å¢ƒ ---
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # å®šä¹‰ token æ˜ å°„
    # ç¡®ä¿è¿™ä¸æ‚¨çš„æ•°æ®é¢„å¤„ç†ä¸€è‡´ï¼
    TOKEN_MAP = {0: 'A', 1: 'C', 2: 'G', 3: 'T', args.blank_id: '<B>'}

    # --- 2. å‡†å¤‡æ•°æ®é›† ---
    print("åŠ è½½æµ‹è¯•æ•°æ®é›†ä¸­...")
    test_dataset_full = BasecallerHDF5Dataset(args.data_file)
    
    if args.num_samples > 0:
        num_samples = min(len(test_dataset_full), args.num_samples)
        print(f"ä½¿ç”¨ {num_samples} ä¸ªéšæœºæ ·æœ¬è¿›è¡Œæµ‹è¯•...")
        # éšæœºæŠ½å–å­é›†
        indices = torch.randperm(len(test_dataset_full))[:num_samples]
        test_dataset = Subset(test_dataset_full, indices)
    else:
        print(f"ä½¿ç”¨å®Œæ•´æµ‹è¯•é›†: {len(test_dataset_full)} ä¸ªæ ·æœ¬")
        test_dataset = test_dataset_full
        
    test_loader = DataLoader(
        test_dataset,
        batch_size=args.batch_size,
        shuffle=False, # è¯„ä¼°æ—¶ä¸éœ€è¦æ‰“ä¹±
        num_workers=args.num_workers,
        pin_memory=True
    )

    # --- 3. åˆå§‹åŒ–æ¨¡å‹ ---
    print("åˆå§‹åŒ–æ¨¡å‹...")
    model = TranscallerLight(
        input_length=args.input_len,
        output_length=args.output_len,
        num_classes=args.num_classes,
        embed_dim=args.embed_dim,
        depth=args.depth,
        num_heads=args.num_heads,
        mlp_ratio=args.mlp_ratio, # ç¡®ä¿æ·»åŠ äº† mlp_ratio
        drop_path_rate=0.0 # è¯„ä¼°æ—¶å…³é—­ drop_path
    ).to(device)
    
    # --- 4. åŠ è½½ Checkpoint ---
    if not os.path.exists(args.checkpoint):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ° Checkpoint æ–‡ä»¶: {args.checkpoint}")
        return
        
    print(f"åŠ è½½ Checkpoint: {args.checkpoint}")
    try:
        # train.py ä¿å­˜çš„æ˜¯ state_dict
        model.load_state_dict(torch.load(args.checkpoint, map_location=device))
    except RuntimeError as e:
        print(f"é”™è¯¯: åŠ è½½ state_dict å¤±è´¥ã€‚")
        print("è¿™é€šå¸¸æ„å‘³ç€æ‚¨çš„æ¨¡å‹æ¶æ„å‚æ•° (embed_dim, depth, heads) ä¸ checkpoint ä¸åŒ¹é…ã€‚")
        print(f"Pytorch é”™è¯¯: {e}")
        return
        
    print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")

    # --- 5. è¿è¡Œå¯è§†åŒ– (å¦‚æœéœ€è¦) ---
    if args.visualize:
        visualize_one_sample(
            model, 
            test_loader, 
            device, 
            TOKEN_MAP, 
            args.blank_id, 
            args.vis_output
        )

    # --- 6. è¿è¡Œå®Œæ•´è¯„ä¼° ---
    print("å¼€å§‹è®¡ç®—å‡†ç¡®æ€§...")
    read_acc, base_acc = evaluate_accuracy(
        model, 
        test_loader, 
        device, 
        args.output_len, 
        args.blank_id
    )
    
    print("\n" + "="*80)
    print("è¯„ä¼°å®Œæˆ!")
    print(f"  Read Accuracy (åºåˆ—å‡†ç¡®ç‡): {read_acc:.2f} %")
    print(f"  Base Accuracy (ç¢±åŸºå‡†ç¡®ç‡): {base_acc:.2f} %")
    print("="*80)

# ==========================================================================================
# æ­¥éª¤ 6: Argparse å‘½ä»¤è¡Œå‚æ•°
# ==========================================================================================

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="è¯„ä¼° TranscallerLight Basecaller æ¨¡å‹")
    
    # --- å…³é”®è·¯å¾„ ---
    parser.add_argument('--data-file', type=str, required=True,
                        help="HDF5 *æµ‹è¯•* æ•°æ®é›†æ–‡ä»¶è·¯å¾„")
    parser.add_argument('--checkpoint', type=str, default="./checkpoints/model_best.pth",
                        help="è¦è¯„ä¼°çš„æ¨¡å‹ .pth æ–‡ä»¶è·¯å¾„")
    
    # --- (Utils) æ•°æ®é›†æ§åˆ¶ ---
    parser.add_argument('--num-samples', type=int, default=-1,
                        help="è¦ä½¿ç”¨çš„æµ‹è¯•æ ·æœ¬æ•°é‡ã€‚-1 è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨ã€‚ (é»˜è®¤: -1)")
    
    # --- (Utils) å¯è§†åŒ– ---
    parser.add_argument('--visualize', action='store_true',
                        help="ç”Ÿæˆä¸€ä¸ªæ ·æœ¬çš„å¯è§†åŒ–å›¾è¡¨")
    parser.add_argument('--vis-output', type=str, default="basecalling_visualization.png",
                        help="å¯è§†åŒ–å›¾è¡¨çš„è¾“å‡ºæ–‡ä»¶å")

    # --- è¯„ä¼°è¶…å‚æ•° ---
    parser.add_argument('--batch-size', type=int, default=128,
                        help="è¯„ä¼°æ—¶çš„æ‰¹é‡å¤§å° (é»˜è®¤: 128)")
    parser.add_argument('--num-workers', type=int, default=8,
                        help="DataLoader ä½¿ç”¨çš„è¿›ç¨‹æ•° (é»˜è®¤: 8)")

    # --- æ¨¡å‹æ¶æ„å‚æ•° (å¿…é¡»ä¸æ‚¨è®­ç»ƒçš„æ¨¡å‹ *å®Œå…¨* åŒ¹é…!) ---
    # 
    # ğŸš€ æ³¨æ„: æˆ‘å·²å°†é»˜è®¤å€¼ä¿®æ”¹ä¸º 'TranscallerLight' çš„æ¨èå€¼ã€‚
    # å¦‚æœæ‚¨è®­ç»ƒæ—¶ä½¿ç”¨äº†å…¶ä»–å€¼, è¯·åœ¨æ­¤å¤„æ˜ç¡®æŒ‡å®šã€‚
    #
    parser.add_argument('--input-len', type=int, default=2048,
                        help="è¾“å…¥ä¿¡å·åºåˆ—é•¿åº¦ (é»˜è®¤: 2048)")
    parser.add_argument('--output-len', type=int, default=420,
                        help="æ¨¡å‹è¾“å‡ºåºåˆ—é•¿åº¦ (é»˜è®¤: 420)")
    parser.add_argument('--num-classes', type=int, default=5,
                        help="ç±»åˆ«æ•° (A,C,G,T,blank) (é»˜è®¤: 5)")
    parser.add_argument('--blank-id', type=int, default=4,
                        help="CTCLoss çš„ç©ºç™½æ ‡ç­¾ ID (é»˜è®¤: 4)")
    
    parser.add_argument('--embed-dim', type=int, default=384,
                        help="Transformer åµŒå…¥ç»´åº¦ (é»˜è®¤: 384)")
    parser.add_argument('--depth', type=int, default=6,
                        help="Transformer å±‚æ•° (é»˜è®¤: 6)")
    parser.add_argument('--num-heads', type=int, default=4,
                        help="Transformer æ³¨æ„åŠ›å¤´æ•° (é»˜è®¤: 4)")
    parser.add_argument('--mlp-ratio', type=float, default=2.0,
                        help="MLP éšè—å±‚æ¯”ä¾‹ (é»˜è®¤: 2.0)")
    
    args = parser.parse_args()
    
    # æ‰“å°æ‰€æœ‰é…ç½®
    print("="*80)
    print("è¯„ä¼°é…ç½®:")
    for k, v in vars(args).items():
        print(f" Â {k}: {v}")
    print("="*80)
    
    main(args)