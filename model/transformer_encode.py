import torch
import torch.nn as nn
import torch.nn.functional as F
import math
from torchinfo import summary
import warnings
from functools import partial
import collections.abc
from itertools import repeat

def _ntuple(n):
    def parse(x):
        if isinstance(x, collections.abc.Iterable) and not isinstance(x, str):
            return tuple(x)
        return tuple(repeat(x, n))
    return parse

to_1tuple = _ntuple(1)
to_2tuple = _ntuple(2)
to_3tuple = _ntuple(3)
to_4tuple = _ntuple(4)
to_ntuple = _ntuple


def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):
    # type: (Tensor, float, float, float, float) -> Tensor
    r"""Fills the input Tensor with values drawn from a truncated
    normal distribution. The values are effectively drawn from the
    normal distribution :math:`\mathcal{N}(\text{mean}, \text{std}^2)`
    with values outside :math:`[a, b]` redrawn until they are within
    the bounds. The method used for generating the random values works
    best when :math:`a \leq \text{mean} \leq b`.

    NOTE: this impl is similar to the PyTorch trunc_normal_, the bounds [a, b] are
    applied while sampling the normal with mean/std applied, therefore a, b args
    should be adjusted to match the range of mean, std args.

    Args:
        tensor: an n-dimensional `torch.Tensor`
        mean: the mean of the normal distribution
        std: the standard deviation of the normal distribution
        a: the minimum cutoff value
        b: the maximum cutoff value
    Examples:
        >>> w = torch.empty(3, 5)
        >>> nn.init.trunc_normal_(w)
    """
    with torch.no_grad():
        return _trunc_normal_(tensor, mean, std, a, b)

def _trunc_normal_(tensor, mean, std, a, b):
    # Cut & paste from PyTorch official master until it's in a few official releases - RW
    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
    def norm_cdf(x):
        # Computes standard normal cumulative distribution function
        return (1. + math.erf(x / math.sqrt(2.))) / 2.

    if (mean < a - 2 * std) or (mean > b + 2 * std):
        warnings.warn("mean is more than 2 std from [a, b] in nn.init.trunc_normal_. "
                      "The distribution of values may be incorrect.",
                      stacklevel=2)

    # Values are generated by using a truncated uniform distribution and
    # then using the inverse CDF for the normal distribution.
    # Get upper and lower cdf values
    l = norm_cdf((a - mean) / std)
    u = norm_cdf((b - mean) / std)

    # Uniformly fill tensor with values from [l, u], then translate to
    # [2l-1, 2u-1].
    tensor.uniform_(2 * l - 1, 2 * u - 1)

    # Use inverse cdf transform for normal distribution to get truncated
    # standard normal
    tensor.erfinv_()

    # Transform to proper mean, std
    tensor.mul_(std * math.sqrt(2.))
    tensor.add_(mean)

    # Clamp to ensure it's in the proper range
    tensor.clamp_(min=a, max=b)
    return tensor

def drop_path(x, drop_prob: float = 0., training: bool = False, scale_by_keep: bool = True):
    """Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).

    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,
    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...
    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for
    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use
    'survival rate' as the argument.

    """
    if drop_prob == 0. or not training:
        return x
    keep_prob = 1 - drop_prob
    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets
    random_tensor = x.new_empty(shape).bernoulli_(keep_prob)
    if keep_prob > 0.0 and scale_by_keep:
        random_tensor.div_(keep_prob)
    return x * random_tensor

class DropPath(nn.Module):
    """Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).
    """
    def __init__(self, drop_prob: float = 0., scale_by_keep: bool = True):
        super(DropPath, self).__init__()
        self.drop_prob = drop_prob
        self.scale_by_keep = scale_by_keep

    def forward(self, x):
        return drop_path(x, self.drop_prob, self.training, self.scale_by_keep)

    def extra_repr(self):
        return f'drop_prob={round(self.drop_prob,3):0.3f}'


class Mlp(nn.Module):
    """ MLP as used in Vision Transformer, MLP-Mixer and related networks

    NOTE: When use_conv=True, expects 2D NCHW tensors, otherwise N*C expected.
    """
    def __init__(
            self,
            in_features,
            hidden_features=None,
            out_features=None,
            act_layer=nn.GELU,
            norm_layer=None,
            bias=True,
            drop=0.,
            use_conv=False,
    ):
        super().__init__()
        out_features = out_features or in_features
        hidden_features = hidden_features or in_features
        bias = to_2tuple(bias)
        drop_probs = to_2tuple(drop)
        linear_layer = partial(nn.Conv2d, kernel_size=1) if use_conv else nn.Linear

        self.fc1 = linear_layer(in_features, hidden_features, bias=bias[0])
        self.act = act_layer()
        self.drop1 = nn.Dropout(drop_probs[0])
        self.norm = norm_layer(hidden_features) if norm_layer is not None else nn.Identity()
        self.fc2 = linear_layer(hidden_features, out_features, bias=bias[1])
        self.drop2 = nn.Dropout(drop_probs[1])

    def forward(self, x):
        x = self.fc1(x)
        x = self.act(x)
        x = self.drop1(x)
        x = self.norm(x)
        x = self.fc2(x)
        x = self.drop2(x)
        return x

class FastEmbed(nn.Module):
    """
    一个基于 1D 卷积的嵌入模块，用于将 1D 原始信号转换为 Transformer 期望的 (B, N, C) 格式。
    
    参数:
        in_chans (int): 输入通道数 (对于原始信号通常是 1)
        in_dim (int): 第一个卷积层的输出通道数 (中间维度)
        embed_dim (int): 最终嵌入维度 (Transformer 的隐藏维度 C)
    """
    def __init__(self, in_chans=1, in_dim=512, embed_dim=1024):
        super().__init__()
        
        # 定义一个包含两个 1D 卷积块的序列
        self.conv_down = nn.Sequential(
            # --- 第 1 块 ---
            # (k=3, s=1, p=1) 是一种 "same" padding，它不会改变序列的长度
            nn.Conv1d(in_chans, in_dim, kernel_size=3, stride=1, padding=1, bias=False),
            # BatchNorm1d 作用于通道维度 (C)
            nn.BatchNorm1d(in_dim, eps=1e-4),
            nn.GELU(approximate='tanh'), # GELU 激活函数

            # --- 第 2 块 ---
            # 同样使用 "same" padding
            nn.Conv1d(in_dim, embed_dim, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm1d(embed_dim, eps=1e-4),
            nn.GELU(approximate='tanh')
        )

    def forward(self, x):
        """
        前向传播。
        输入 x 形状: (B, C_in, N)  -> (Batch, 1, 4096)
        """
        
        # 1. 通过卷积块
        # x 形状: (B, C_in, N) -> (B, embed_dim, N)
        # 例如: (B, 1, 4096) -> (B, 1024, 4096)
        x = self.conv_down(x)
        
        # 2. 调整维度顺序
        # Transformer 期望的输入格式是 (B, N, C) 即 (Batch, Sequence, Channels)
        # x 形状: (B, embed_dim, N) -> (B, N, embed_dim)
        # 例如: (B, 1024, 4096) -> (B, 4096, 1024)
        x = x.transpose(1, 2)
        
        return x


class Attention(nn.Module):
    """
    标准的多头自注意力 (Multi-Head Self-Attention) 模块。
    它使用了 PyTorch 2.0 中内置的 F.scaled_dot_product_attention 来优化计算。
    
    参数:
        dim (int): 输入的嵌入维度 (C)
        num_heads (int): 注意力头的数量。dim 必须能被 num_heads 整除。
        qkv_bias (bool): 是否为 Q, K, V 线性层添加偏置
        attn_drop (float): 注意力图 (scores) 的 dropout 概率
        proj_drop (float): 最终输出的 dropout 概率
    """
    def __init__(self, dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0.):
        super().__init__()
        assert dim % num_heads == 0, "dim 必须能被 num_heads 整除"
        
        self.num_heads = num_heads
        self.head_dim = dim // num_heads  # 每个头的维度
        # self.scale = self.head_dim ** -0.5 # F.scaled_dot_product_attention 会自动处理 scale

        # 1. QKV 投影层
        # 一个单独的线性层，一次性计算出 Q, K, V
        # (dim) -> (dim * 3)
        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)
        
        # 2. 注意力 Dropout
        self.attn_drop = nn.Dropout(attn_drop) # 注意：F.scaled_dot_product_attention 接受 p 作为参数

        # 3. 输出投影层
        # 将多头注意力的结果重新投影回原始维度
        self.proj = nn.Linear(dim, dim)
        self.proj_drop = nn.Dropout(proj_drop)

    def forward(self, x):
        """
        前向传播。
        输入 x 形状: (B, N, C) -> (Batch, 4096, 1024)
        """
        B, N, C = x.shape # B=Batch, N=序列长度, C=嵌入维度

        # 1. 计算 Q, K, V
        # x -> qkv(x): (B, N, C) -> (B, N, 3 * C)
        # reshape: (B, N, 3 * C) -> (B, N, 3, num_heads, head_dim)
        # permute: (B, N, 3, num_heads, head_dim) -> (3, B, num_heads, N, head_dim)
        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)

        # 2. 分离 Q, K, V
        # qkv.unbind(0) 会在第 0 维 (大小为 3) 上解绑
        # q, k, v 形状均为: (B, num_heads, N, head_dim)
        q, k, v = qkv.unbind(0) 

        # 3. 计算缩放点积注意力
        # 这是 PyTorch 2.0 的高效实现，它融合了 scale, matmul, softmax, dropout 和 matmul(V)
        # 输出 x 形状: (B, num_heads, N, head_dim)
        x = F.scaled_dot_product_attention(
            q, k, v, 
            dropout_p=self.attn_drop.p  # 传递 dropout 概率
        )

        # 4. 重新组合多头
        # transpose: (B, num_heads, N, head_dim) -> (B, N, num_heads, head_dim)
        # reshape: (B, N, num_heads, head_dim) -> (B, N, C) (其中 C = num_heads * head_dim)
        x = x.transpose(1, 2).reshape(B, N, C)

        # 5. 通过最终的投影层和 dropout
        # (B, N, C) -> (B, N, C)
        x = self.proj(x)
        x = self.proj_drop(x)
        
        return x

class TransformerBlock(nn.Module):
    """
    一个标准的 Transformer 编码器块。
    结构:
        1. Pre-Normalization (LayerNorm)
        2. Multi-Head Attention (self.mixer)
        3. Residual Connection + DropPath
        4. Pre-Normalization (LayerNorm)
        5. MLP (Feed-Forward Network)
        6. Residual Connection + DropPath
        
    参数:
        dim (int): 嵌入维度 (C)
        num_heads (int): 注意力头数量
        mlp_ratio (float): MLP 中间隐藏层维度相对于 dim 的比例
        qkv_bias (bool): 是否为 Attention 的 QKV 添加偏置
        drop (float): MLP 和 Proj 层的 dropout
        attn_drop (float): 注意力层的 dropout
        drop_path (float): 随机深度 (Stochastic Depth) 的 dropout 概率
        act_layer: 激活函数, 默认为 nn.GELU
        norm_layer: 归一化层, 默认为 nn.LayerNorm
    """
    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, drop=0., 
                 attn_drop=0., drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):
        super().__init__()
        
        # 第 1 个子层：自注意力
        self.norm1 = norm_layer(dim)
        self.mixer = Attention( # mixer 是一个通用词，这里特指 Attention
            dim, num_heads=num_heads, qkv_bias=qkv_bias, 
            attn_drop=attn_drop, proj_drop=drop
        )
        
        # 随机深度 (DropPath)，如果 drop_path=0, 则为 nn.Identity()
        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()
        
        # 第 2 个子层：MLP (前馈网络)
        self.norm2 = norm_layer(dim)
        mlp_hidden_dim = int(dim * mlp_ratio) # 计算 MLP 的中间维度
        self.mlp = Mlp(
            in_features=dim, 
            hidden_features=mlp_hidden_dim, 
            act_layer=act_layer, 
            drop=drop
        )

    def forward(self, x):
        """
        前向传播。
        输入 x 形状: (B, N, C)
        """
        
        # 1. 第一个子层 (Attention)
        # Pre-Normalization: 先归一化，再送入 Attention
        # Residual Connection: x + ...
        # x 形状: (B, N, C) -> (B, N, C)
        x = x + self.drop_path(self.mixer(self.norm1(x)))
        
        # 2. 第二个子层 (MLP)
        # Pre-Normalization: 先归一化，再送入 MLP
        # Residual Connection: x + ...
        # x 形状: (B, N, C) -> (B, N, C)
        x = x + self.drop_path(self.mlp(self.norm2(x)))
        
        return x

class Head(nn.Module):
    """
    模型的输出头，负责下采样序列长度和进行分类投影。
    
    参数:
        in_features (int): 输入特征维度 (C)
        seq_len (int): 输入序列长度 (N_in), (这个参数在代码中实际未使用)
        out_seq_len (int): 目标输出序列长度 (N_out)
        num_classes (int): 最终分类的数量
    """
    def __init__(self, in_features, seq_len, out_seq_len, num_classes):
        super().__init__()
        
        # 1. 自适应平均池化
        # AdaptiveAvgPool1d 会在 1D 维度 (这里是序列长度 N) 上进行池化
        # 它会自动计算所需的 kernel_size 和 stride，以将任意输入长度池化到 `out_seq_len`
        self.adaptive_pool = nn.AdaptiveAvgPool1d(out_seq_len)
        
        # 2. 分类投影层
        # 一个线性层，将 C_in 维度投影到 num_classes 维度
        self.out_proj = nn.Linear(in_features, num_classes)

    def forward(self, x):
        """
        前向传播。
        输入 x 形状: (B, N_in, C) -> (B, 4096, 1024)
        """
        
        # 1. 调整维度以适应 1D 池化
        # nn.AdaptiveAvgPool1d 期望的输入是 (B, C, N)
        # x 形状: (B, N_in, C) -> (B, C, N_in)
        # 例如: (B, 4096, 1024) -> (B, 1024, 4096)
        x = x.transpose(1, 2)
        
        # 2. 应用池化
        # x 形状: (B, C, N_in) -> (B, C, N_out)
        # 例如: (B, 1024, 4096) -> (B, 1024, 420)
        x = self.adaptive_pool(x)
        
        # 3. 恢复为 (B, N, C) 格式
        # x 形状: (B, C, N_out) -> (B, N_out, C)
        # 例如: (B, 1024, 420) -> (B, 420, 1024)
        x = x.transpose(1, 2)

        # 4. 应用分类投影
        # 线性层会作用于最后一个维度 (C)
        # x 形状: (B, N_out, C) -> (B, N_out, num_classes)
        # 例如: (B, 420, 1024) -> (B, 420, 5)
        x = self.out_proj(x)
        
        # 5. 调整为 CTC Loss 期望的格式
        # CTCLoss 期望的输入格式是 (T, B, C)，即 (Seq_Len, Batch, Classes)
        # x 形状: (B, N_out, num_classes) -> (N_out, B, num_classes)
        # 例如: (B, 420, 5) -> (420, B, 5)
        return x.permute(1, 0, 2)


class Transcaller(nn.Module):
    """
    完整的 Melchior 模型架构。
    
    参数:
        in_chans (int): 输入信号通道数
        embed_dim (int): Transformer 内部的嵌入维度
        depth (int): TransformerBlock 的层数
        num_heads (int): 注意力头数量
        mlp_ratio (float): MLP 隐藏层比例
        qkv_bias (bool): 是否使用 QKV 偏置
        drop_rate (float): MLP/Proj 的 dropout
        attn_drop_rate (float): 注意力的 dropout
        drop_path_rate (float): 随机深度的最大 dropout 概率
        output_length (int): 最终输出序列的长度
        num_classes (int): 最终分类数
    """
    # 1. 在这里添加 input_length 参数
    def __init__(self, in_chans=1, embed_dim=1024, depth=20, num_heads=8, mlp_ratio=4.,
                 qkv_bias=False, drop_rate=0., attn_drop_rate=0., drop_path_rate=0.1,
                 input_length=4096, output_length=420, num_classes=5): # <-- 添加 input_length
        super().__init__()
        self.stem = FastEmbed(in_chans=in_chans, in_dim=512, embed_dim=embed_dim)
        
        # 2. 使用 input_length 代替 4096
        self.pos_embed = nn.Parameter(torch.zeros(1, input_length, embed_dim)) # <-- 已修正
        trunc_normal_(self.pos_embed, std=.02)
        trunc_normal_(self.pos_embed, std=.02) # 使用截断正态分布初始化

        # 3. 随机深度 (Stochastic Depth) 衰减规则
        # 创建一个从 0 线性增加到 drop_path_rate 的概率列表
        # 浅层 (i=0) 的 drop_path 概率为 0
        # 深层 (i=depth-1) 的 drop_path 概率为 drop_path_rate
        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]
        
        # 4. Transformer 编码器堆栈
        # 使用 nn.ModuleList 来存储所有的 TransformerBlock
        self.blocks = nn.ModuleList([
            TransformerBlock(
                dim=embed_dim,
                num_heads=num_heads,
                mlp_ratio=mlp_ratio,
                qkv_bias=qkv_bias,
                drop=drop_rate,
                attn_drop=attn_drop_rate,
                drop_path=dpr[i], # 为每一层传递不同的 drop_path 概率
                norm_layer=nn.LayerNorm
            )
            for i in range(depth) # 创建 depth 个块
        ])
        
        # 5. 最终的归一化层
        # 在进入输出头之前，对 Transformer 的输出进行归一化
        self.norm = nn.LayerNorm(embed_dim)
        
        # 6. 输出头
        self.head = Head(embed_dim, input_length, output_length, num_classes=num_classes)
        
    def forward(self, x):
        """
        完整的前向传播。
        输入 x 形状: (B, 1, 4096)
        """
        
        # 1. 嵌入
        # x 形状: (B, 1, 4096) -> (B, 4096, embed_dim)
        x = self.stem(x)
        
        # 2. 添加位置编码
        # (B, 4096, embed_dim) + (1, 4096, embed_dim)
        # (利用了广播机制)
        x = x + self.pos_embed
        
        # 3. 通过所有 Transformer 块
        # x 形状保持不变: (B, 4096, embed_dim)
        for block in self.blocks:
            x = block(x)
            
        # 4. 最终归一化
        # x 形状: (B, 4096, embed_dim)
        x = self.norm(x)
        
        # 5. 通过输出头
        # x 形状: (B, 4096, embed_dim) -> (420, B, 5)
        x = self.head(x)
        
        # 6. 计算对数概率
        # (CTCLoss 期望对数概率作为输入)
        # F.log_softmax 作用于最后一个维度 (dim=-1), 即类别维度
        # 输出形状: (420, B, 5)
        return F.log_softmax(x, dim=-1)

# ==========================================================================================
# 主函数：实例化和测试
# ==========================================================================================
if __name__ == '__main__':
    # --- 1. 配置和参数 ---
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # 模型参数 (使用了示例中的参数)
    BATCH_SIZE = 4 
    EMBED_DIM = 768    # 嵌入维度
    DEPTH = 12         # Transformer 层数
    NUM_HEADS = 6      # 注意力头数
    SEQ_LEN = 2048     # 输入序列长度
    OUTPUT_LEN = 420   # 输出序列长度
    NUM_CLASSES = 5    # 分类数 {A, C, G, T, <blank>}

    # --- 2. 实例化模型 ---
    model = Transcaller(
        input_length=SEQ_LEN,
        embed_dim=EMBED_DIM,
        depth=DEPTH,
        num_heads=NUM_HEADS,
        output_length=OUTPUT_LEN,
        num_classes=NUM_CLASSES
    ).to(device)

    # --- 3. 使用 torchinfo 打印架构摘要 ---
    print("\n" + "="*80)
    print("模型架构摘要 (重构注释版)")
    print("="*80)
    
    # 定义 torchinfo 需要的输入大小
    # (batch_size, in_channels, sequence_length)
    input_size = (BATCH_SIZE, 1, SEQ_LEN)
    
    # 打印摘要
    summary(model, input_size=input_size, device=device)
    
    # --- 4. (可选) 测试一次前向传播 ---
    print("\n" + "="*80)
    print("测试一次前向传播...")
    print(f"创建随机输入: {input_size}")
    dummy_input = torch.randn(input_size).to(device)
    
    with torch.no_grad(): # 关闭梯度计算
        output = model(dummy_input)
        
    print(f"模型成功执行！")
    print(f"最终输出形状: {output.shape} (应为: {OUTPUT_LEN, BATCH_SIZE, NUM_CLASSES})")
    print("="*80)